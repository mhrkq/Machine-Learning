{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3937548,"sourceType":"datasetVersion","datasetId":2337399}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.decomposition import PCA\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import f1_score\nimport matplotlib.pyplot as plt\n\ndef load_data(file_path, is_train=True):\n    data = pd.read_csv(file_path)\n    if is_train:\n        X = data.iloc[:, 1:].values  # Features (assuming all columns are features)\n        y = data.iloc[:, 0].values   # Target variable (assuming first column is label)\n        return X, y\n    else:\n        X = data.values  # Features (assuming all columns are features)\n        return X\n\ndef normalise(X):\n    X_mean = X.mean(axis=0)\n    X_std = X.std(axis=0)\n    # Handling zero standard deviation to avoid division by zero\n    zero_std_mask = X_std == 0\n    X_normalised = np.zeros_like(X)\n    X_normalised[:, ~zero_std_mask] = (X[:, ~zero_std_mask] - X_mean[~zero_std_mask]) / X_std[~zero_std_mask]\n    X_normalised[:, zero_std_mask] = X[:, zero_std_mask] - X_mean[zero_std_mask]\n    return X_normalised\n\ndef apply_pca(X_train, X_test, n_components):\n    pca = PCA(n_components=n_components)\n    X_train_pca = pca.fit_transform(X_train)\n    X_test_pca = pca.transform(X_test)\n    return X_train_pca, X_test_pca\n\ndef train_knn(X_train, y_train, n_neighbors=2):\n    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n    knn.fit(X_train, y_train)\n    return knn\n\ndef predict_knn(knn, X_test):\n    return knn.predict(X_test)\n\ndef evaluate_model(y_true, y_pred):\n    return f1_score(y_true, y_pred, average='macro')\n\nfile_path_train = \"/kaggle/input/mlprojectdataset/train_tfidf_features.csv\"\nfile_path_test = \"/kaggle/input/mlprojectdataset/test_tfidf_features.csv\"\nX_train, y_train = load_data(file_path_train, is_train=True)\nX_test = load_data(file_path_test, is_train=False)\n\nX_train = normalise(X_train)\nX_test = normalise(X_test)\n\npca_components = [2000, 1000, 500, 100]\nresults = {}\n\nfor n in pca_components:\n    print(f'Applying PCA with {n} components...')\n    \n    # Apply PCA\n    X_train_pca, X_test_pca = apply_pca(X_train, X_test, n_components=n)\n    \n    # Train KNN\n    knn = train_knn(X_train_pca, y_train, n_neighbors=2)\n    \n    # Predict on test set\n    y_test_pred = predict_knn(knn, X_test_pca)\n    \n    # Save the predictions to a CSV file\n    prediction_file = f\"KNN_Prediction_{n}.csv\"\n    pd.DataFrame(y_test_pred, columns=[\"label\"]).to_csv(prediction_file, index=False)\n    \n# Submit the predictions to Kaggle to get the Macro F1 score","metadata":{},"execution_count":null,"outputs":[]}]}